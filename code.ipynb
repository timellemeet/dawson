{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "master_thesis",
      "provenance": [],
      "collapsed_sections": [
        "nQx_SE-6J2af",
        "uCe1OVU5LLWJ",
        "wE-CnVYQ6GOG",
        "P3-lItz4oCJV",
        "4FQfvgFig3Dd",
        "3USahyqPv3RB",
        "Bc750Ec5vvHv",
        "v4diqoYqvqqJ",
        "EAbt5bieobWv",
        "AqbItFXVJ8y2",
        "lfvfXRSrstrA",
        "HcFgeT8Xsz3d",
        "-8dj6s3Os3yN",
        "QvZjC1wbJbc7",
        "9QEqSOh15qeD"
      ],
      "machine_shape": "hm",
      "mount_file_id": "1aIjS90CRf3138TTt9tP3vNjbOx2oZXbD",
      "authorship_tag": "ABX9TyPbjVsdJt7Xd6oSbLpt+aKI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/timellemeet/73087b0e0c49b2b0fbe1c570ce948708/copy-of-thesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d88Pe4LRvvQH"
      },
      "source": [
        "%reset -s -f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0_HsOjjJ4Q9"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers==4.3.3 wandb tensorflow_addons --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HznZdSdAGxud"
      },
      "source": [
        "Logging to Weights & Biases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDQt9tIEPsWH"
      },
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "wandb.login(key=[YOUR API KEY HERE])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7QfKr-L5qa2"
      },
      "source": [
        "Define the configuration of the experiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly5VPP6X5uHk"
      },
      "source": [
        "import secrets\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "from transformers import logging as hf_logging\n",
        "\n",
        "PRETRAINED_MODEL = \"bert-base-uncased\"\n",
        "\n",
        "SHOW_MASKS = True\n",
        "\n",
        "SKIP_RUNS = 0\n",
        "\n",
        "config = {\n",
        "# General\n",
        "\"name\": \"Main\",\n",
        "\"remark\": \"Full experiment with proposed metrics\",\n",
        "\"dataset\": [\"SST-2\",\"QQP\",\"QNLI\"][0],\n",
        "\"target_size\":0.01,\n",
        "\"n_experiments\": 15,\n",
        "\"label_type\": [\"natural\",\"token\"][0],\n",
        "\n",
        "# SpanBERT\n",
        "\"spanbert\": True,\n",
        "\"n_spanbert_repeat\":10,\n",
        "\"span_clip_multiplier\":2,\n",
        "\"span_clip_max\":10,\n",
        "\"sb_epochs\":10,\n",
        "\n",
        "# Span Extraction\n",
        "# \"spex\":  [False, \"finetune\",\"pretrain\",\"both\"][0], # False / finetune, pretrain, both\n",
        "\"spex_mode\": [\"span\", \"token\"][0], \n",
        "\"spex_pt_epochs\": 10,\n",
        "\"spex_ft_epochs\": 10,\n",
        "\"shuffle_labels\": True,\n",
        "\"ws_mean\": 0.57,\n",
        "\"ws_var\": 0.05,\n",
        "\"ws_histogram\": False,\n",
        "\"ws_metrics\": False,\n",
        "\n",
        "# # Target Analysis\n",
        "# \"ta_epochs\": 1,\n",
        "\n",
        "# Augmentation\n",
        "\"augmentation\": [False, \"base\",\"hetero\"][0], # natural / token / heterogenous (inc target analysis)\n",
        "\"n_train_aug\": 10,\n",
        "\"n_target_aug\": 2,\n",
        "\"aug_epochs\": 15, #later set to 10 #################################\n",
        "\"probabilistic_labels\": True,\n",
        "\"min_weak_prob\": 0.55,\n",
        "\"mask_prob\": 0.15, \n",
        "\"attention_multiplier\": 3,\n",
        "\"UB\":1.,\n",
        "\"LB\":0.6,\n",
        "\n",
        "# Finetuning\n",
        "# \"finetune_am\": False,\n",
        "\"extrinsic_epochs\": 30,\n",
        "\"extrinsic_batch_size\": 16,\n",
        "\"eval_epochs\": 10,\n",
        "\"eval_batch_size\": 32,\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "\"seed\":1234,\n",
        "\"batch_size\": 32,\n",
        "\"shuffle_batches\": 5,\n",
        "\"max_length\": 200, ##\n",
        "\"smart_batching\":True,\n",
        "\"fast_tokenizer\": True,\n",
        "\"optimizer_lr\": 2e-5,\n",
        "\"optimizer_epsilon\": 1e-8\n",
        "}\n",
        "\n",
        "# logging.basicConfig(level=logging.WARNING)\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.autograph.set_verbosity(0)\n",
        "hf_logging.set_verbosity_error()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQx_SE-6J2af"
      },
      "source": [
        "### GPU\n",
        "Get information about the GPU given by Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMJhgDScJ1MW"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCe1OVU5LLWJ"
      },
      "source": [
        "# Dataset processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE-CnVYQ6GOG"
      },
      "source": [
        "### Dataset loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygV9XPETAY9Q"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_dataset(dataset, split, head=True, return_class_names=False):\n",
        "  df = pd.read_csv(f\"/content/drive/Shareddrives/Thesis/datasets/{dataset}/{split}.tsv\", sep='\\t',  error_bad_lines=False)\n",
        "\n",
        "  if dataset == \"SST-2\":\n",
        "    df.rename(columns={\"sentence\": \"text\"}, inplace=True)\n",
        "    class_names = [\"Negative\", \"Positive\"]\n",
        "\n",
        "  elif dataset == \"QQP\":\n",
        "    df.rename(columns={\"question1\": \"text\", \"question2\": \"text_pair\", \"is_duplicate\":\"label\"}, inplace=True)\n",
        "    df.drop(columns=[\"id\", \"qid1\",\"qid2\"], inplace=True)\n",
        "    class_names = [\"Different\", \"Similar\"]\n",
        "\n",
        "  elif dataset == \"QNLI\":\n",
        "    df.rename(columns={\"question\": \"text\", \"sentence\": \"text_pair\"}, inplace=True)\n",
        "    df.drop(columns=[\"index\"], inplace=True)\n",
        "    df.label = df.label.apply(lambda x: 1 if x == \"entailment\" else 0)\n",
        "    class_names = [\"Missing\", \"Entailed\"]\n",
        "\n",
        "  if head: \n",
        "    display(df.head())\n",
        "    \n",
        "  if return_class_names:\n",
        "    return df, class_names\n",
        "  else:\n",
        "    return df\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3-lItz4oCJV"
      },
      "source": [
        "### Prepending strategies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcGp349-GTQM"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "              PRETRAINED_MODEL, \n",
        "              use_fast=config[\"fast_tokenizer\"])\n",
        "\n",
        "if config[\"label_type\"] == \"token\":\n",
        "  label_names = [\"[NEG]\", \"[POS]\"]\n",
        "  tokenizer.add_special_tokens({'additional_special_tokens': label_names})\n",
        "else:\n",
        "  #natural tokens\n",
        "  label_names = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RvmR56ToE-0"
      },
      "source": [
        "from random import sample\n",
        "def prepend_labels(df, task):\n",
        "  if task ==\"augmentation\":\n",
        "    mapping = lambda row: f\"{label_names[row.label]} {row.text}\"\n",
        "  elif task==\"spex\":\n",
        "    #SHUFFLE LABELS TO PREVENT POSITION FITTING\n",
        "\n",
        "    if config[\"shuffle_labels\"]:\n",
        "      shuffled_labels = lambda: sample(label_names, len(label_names))\n",
        "      mapping = lambda row: \" \".join([*shuffled_labels(), row.text])\n",
        "\n",
        "    else:\n",
        "      mapping = lambda row: \" \".join([*label_names, row.text])\n",
        "\n",
        "  text = df.apply(mapping, axis=1)\n",
        "  \n",
        "  #make prepend maks\n",
        "  label_ids = tokenizer(label_names, add_special_tokens=False).input_ids\n",
        "\n",
        "  return text, label_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbZN3gqbRoQ4"
      },
      "source": [
        "def decode_inputs(inputs):\n",
        "  head = inputs[\"input_ids\"][:5]\n",
        "  for row in head:\n",
        "    print(tokenizer.decode(row).replace(\" [PAD]\", \"\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz1bTGdfifbN"
      },
      "source": [
        "## Task processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FQfvgFig3Dd"
      },
      "source": [
        "### Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmsBiLqxeulI"
      },
      "source": [
        "def classification_preprocessing(inputs, df):\n",
        "  prob_1 = df.label.values \n",
        "  prob_0 = 1 - prob_1\n",
        "  labels = np.vstack((prob_0, prob_1)).T\n",
        "  \n",
        "  return inputs, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3USahyqPv3RB"
      },
      "source": [
        "### SpanBERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ideecba3et4g"
      },
      "source": [
        "from itertools import accumulate\n",
        "\n",
        "def spanbert_preprocessing(inputs, df):\n",
        "  normal_tokens_mask = inputs[\"attention_mask\"]*(1-inputs[\"special_tokens_mask\"])\n",
        "\n",
        "  #set boundary normal tokens to zero such that spans are not allowed to go there\n",
        "  boundary_indices = np.diff(normal_tokens_mask, n=1)\n",
        "  boundary_indices = boundary_indices.nonzero()\n",
        "  boundary_indices[1][::2] +=1 #due to difference we need to move start positions (uneven) one position.\n",
        "  normal_tokens_mask[boundary_indices] = 0  \n",
        "\n",
        "  #filter out samples where there are no candiate tokens left (too short)\n",
        "  n_normal_tokens = normal_tokens_mask.sum(axis=1) \n",
        "  filter = n_normal_tokens > 0\n",
        "\n",
        "  n_normal_tokens = n_normal_tokens[filter]\n",
        "  normal_tokens_mask = normal_tokens_mask[filter]\n",
        "  inputs = {key: value[filter] for key, value in inputs.items()}\n",
        "  \n",
        "\n",
        "  #reverse count normal token spans to see where the span mask fits.\n",
        "  flipped = np.flip(normal_tokens_mask,axis=1)\n",
        "  cumsum_f = lambda row: list(accumulate(row, lambda acc, elem: acc + elem if elem else 0))\n",
        "  flipped_cumsum = np.array([cumsum_f(row) for row in flipped])\n",
        "  cumsum_mask = np.flip(flipped_cumsum,axis=1)\n",
        "  \n",
        "  #copy dataset if repeat for multiple epochs\n",
        "  if config[\"n_spanbert_repeat\"] > 1:\n",
        "    inputs = {key:  np.tile(value, (config[\"n_spanbert_repeat\"], 1)) for key, value in inputs.items()}\n",
        "    n_normal_tokens = np.tile(n_normal_tokens, config[\"n_spanbert_repeat\"])\n",
        "    cumsum_mask = np.tile(cumsum_mask, (config[\"n_spanbert_repeat\"], 1))\n",
        "\n",
        "  #sample the span lengths\n",
        "  geometric_means = config[\"mask_prob\"] * n_normal_tokens\n",
        "  geometric_probs = 1/geometric_means\n",
        "  geometric_probs = np.minimum(geometric_probs, 1) #clip\n",
        "  \n",
        "  span_lengths = np.random.geometric(geometric_probs)\n",
        "  span_lengths = np.minimum(span_lengths, config[\"span_clip_multiplier\"] * geometric_means)\n",
        "  span_lengths = np.minimum(span_lengths, config[\"span_clip_max\"])\n",
        "\n",
        "  #Make sure span length doesnt exceed any candidate spans\n",
        "  span_lengths = np.minimum(span_lengths, np.amax(cumsum_mask, axis=-1))\n",
        "\n",
        "  #boolean if indices are valid starting positions, by comparing to span length\n",
        "  candidate_indices = np.greater_equal(cumsum_mask, span_lengths[:,None]).astype(float)\n",
        "  candidate_probs = candidate_indices / candidate_indices.sum(axis=-1)[:,None]\n",
        "  \n",
        "  #sample span locations\n",
        "  masked_indices = np.array([np.random.multinomial(n=1, pvals=row) for row in candidate_probs])\n",
        "  _, starting_indices = np.where(masked_indices==1)\n",
        "  for i, span in enumerate(span_lengths):\n",
        "    s = starting_indices[i]\n",
        "    e = int(s+span)\n",
        "    masked_indices[i, s:e] = 1\n",
        "\n",
        "  # get pair indices for SBO loss\n",
        "  pair_indices = np.diff(masked_indices, n=1).nonzero()[1] #take indices of diff cols\n",
        "  pair_indices = pair_indices.reshape(-1, 2) #shape vector to matrix (:,2)\n",
        "  pair_indices[:,1] += 1 #adjust for diff position\n",
        "  inputs[\"pair_indices\"] = pair_indices\n",
        "  inputs[\"masked_indices\"] = masked_indices\n",
        "\n",
        "  # tokens with -100 are ignored for the loss, othwerise input id of token\n",
        "  labels = np.copy(inputs[\"input_ids\"])\n",
        "  labels = labels * masked_indices\n",
        "  labels[labels == 0] = -100\n",
        "\n",
        "  #masking strategies: 80% replaced mask, 10% random, 10% original (not removed)\n",
        "  mask_types = np.random.multinomial(n=1, \n",
        "                          pvals=[0.8, 0.1, 0.1],\n",
        "                          size=len(masked_indices))\n",
        "  \n",
        "  indices_replaced = mask_types[:,0, None] * masked_indices\n",
        "  indices_random = mask_types[:,1, None] * masked_indices\n",
        "  indices_filter = 1 - (indices_replaced + indices_random) #\n",
        "  \n",
        "  #draw random tokens\n",
        "  all_tokens = list(tokenizer.get_vocab().values())\n",
        "  normal_tokens = [t for t in all_tokens if t not in tokenizer.all_special_ids]\n",
        "  random_words = np.random.choice(normal_tokens, size=labels.shape)\n",
        "\n",
        "  #remove tokens for mask and replace \n",
        "  inputs[\"input_ids\"] *= indices_filter \n",
        "  inputs[\"input_ids\"] += indices_replaced * tokenizer.mask_token_id\n",
        "  inputs[\"input_ids\"] += indices_random * random_words\n",
        "  \n",
        "  return inputs, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bc750Ec5vvHv"
      },
      "source": [
        "### Span Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzu7JuT8esFf"
      },
      "source": [
        "#scan for positions test\n",
        "def find_positions(sequence, ids):\n",
        "  label_lengths = len(ids) \n",
        "  #search for consecutive \n",
        "  if label_lengths > 1:\n",
        "    consecutive = False\n",
        "    start = 0\n",
        "    while not consecutive:\n",
        "      positions = [sequence.index(t, start) for t in ids]\n",
        "      consecutive = np.array_equal(np.diff(positions), np.ones(label_lengths-1))\n",
        "\n",
        "      if not consecutive:\n",
        "        start = min(positions) + 1\n",
        "\n",
        "    start_position =  positions[0]\n",
        "    end_position = positions[-1]   \n",
        "    \n",
        "  else:\n",
        "    start_position =  sequence.index(ids[0])\n",
        "    end_position = start_position\n",
        "\n",
        "  return start_position, end_position\n",
        "\n",
        "\n",
        "def spex_preprocessing(inputs, df, label_ids):\n",
        "  inputs, label_probs = classification_preprocessing(inputs, df)\n",
        "\n",
        "  shape = inputs[\"input_ids\"].shape\n",
        "  start_labels = np.zeros(shape)\n",
        "  end_labels = np.zeros(shape)\n",
        "\n",
        "  for i, row in enumerate(inputs[\"input_ids\"].tolist()):\n",
        "    pos_0_s, pos_0_e = find_positions(row, label_ids[0])\n",
        "    pos_1_s, pos_1_e = find_positions(row, label_ids[1])\n",
        "\n",
        "    start_labels[i, pos_0_s] = label_probs[i, 0]\n",
        "    start_labels[i, pos_1_s] = label_probs[i, 1]\n",
        "    \n",
        "    end_labels[i, pos_0_e] = label_probs[i, 0]\n",
        "    end_labels[i, pos_1_e] = label_probs[i, 1]\n",
        "\n",
        "  if config[\"spex_mode\"] == \"span\":\n",
        "    labels = np.stack([start_labels, end_labels], axis=1)\n",
        "  elif config[\"spex_mode\"] == \"token\":\n",
        "    if max([len(l) for l in label_ids]) > 1: \n",
        "      raise Exception(\"Token model cant be used for natural labels with multiple tokens\")\n",
        "    else:\n",
        "      labels = start_labels\n",
        "\n",
        "  else:\n",
        "    print(config[\"spex_mode\"])\n",
        "    raise Exception(\"No labels defined\")\n",
        "  return inputs, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4diqoYqvqqJ"
      },
      "source": [
        "### Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTpn1yt8oYko"
      },
      "source": [
        "def augmentation_preprocessing(inputs, df, label_ids, train, mask_strategy, repeat=1, analysis=None):\n",
        "  df_labels = df.label.values\n",
        "  #copy dataset for \"dynamic\" token masking\n",
        "  if repeat > 1:\n",
        "    inputs = {key:  np.tile(value, (repeat, 1)) for key, value in inputs.items()}\n",
        "    df_labels = np.tile(df_labels, repeat)\n",
        "\n",
        "  labels = np.copy(inputs[\"input_ids\"])\n",
        "\n",
        "  #make prepend mask to prevent label masking\n",
        "  label_lengths = [len(label) for label in label_ids]\n",
        "  \n",
        "  prepend_mask = np.zeros(labels.shape, dtype=int)\n",
        " \n",
        "  for i, row in enumerate(prepend_mask):\n",
        "    label = df_labels[i]\n",
        "    label_ids_length = label_lengths[label]\n",
        "    row[1:label_ids_length+1] = 1\n",
        "\n",
        "  inputs[\"special_tokens_mask\"] += prepend_mask\n",
        "\n",
        "  #determine which tokens to mask\n",
        "  if mask_strategy == \"base\":\n",
        "    #random masking\n",
        "    masked_indices = np.random.binomial(n=1, p=config[\"mask_prob\"],size=labels.shape) * (inputs[\"special_tokens_mask\"] == 0) \n",
        "\n",
        "  elif mask_strategy == \"hetero\":\n",
        "    complexity, attentions = analysis\n",
        "\n",
        "    if repeat > 1:\n",
        "      complexity, attentions =  np.tile(complexity, repeat), np.tile(attentions, (repeat, 1))\n",
        "\n",
        "    max_length = inputs[\"special_tokens_mask\"].shape[1]\n",
        "    attentions = attentions[:, :max_length]\n",
        "    \n",
        "    inputs[\"complexity\"] = complexity\n",
        "    \n",
        "    #remove special tokens and reweight probs\n",
        "    special_token_probs = (attentions * inputs[\"special_tokens_mask\"]).sum(axis=1)\n",
        "    attentions *= (inputs[\"special_tokens_mask\"] == 0) \n",
        "    normal_token_probs = attentions.sum(axis=1)\n",
        "    redistribution_weights = attentions/normal_token_probs[:,None]\n",
        "    extra_weights = redistribution_weights * special_token_probs[:,None]\n",
        "    attentions += extra_weights\n",
        "\n",
        "    #remove mean\n",
        "    attentions -= (1/ np.count_nonzero(attentions, axis=1))[:,None]\n",
        "    attentions *= config[\"attention_multiplier\"]\n",
        "    attentions += 1\n",
        "    attentions *= (inputs[\"special_tokens_mask\"] == 0) \n",
        "\n",
        "    #multiply weights with probability\n",
        "    attentions *= config[\"mask_prob\"]\n",
        "    \n",
        "    #clip elementwise probs\n",
        "    attentions = np.clip(attentions, 0, 1)\n",
        "    \n",
        "    masked_indices = np.random.binomial(n=1, p=attentions) * (inputs[\"special_tokens_mask\"] == 0)  \n",
        "\n",
        "  #filter out samples where no masks\n",
        "  n_masked_tokens = masked_indices.sum(axis=1) \n",
        "  filter = n_masked_tokens > 0\n",
        "\n",
        "  masked_indices = masked_indices[filter]\n",
        "  inputs = {key: value[filter] for key, value in inputs.items()}\n",
        "  df_labels = df_labels[filter]\n",
        "  labels = labels[filter]\n",
        "\n",
        "  if train:\n",
        "    # tokens with -100 are ignored for the loss, othwerise input id of token\n",
        "    labels = labels * masked_indices\n",
        "    labels[labels == 0] = -100\n",
        "\n",
        "    # 80% (replace_prob) of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
        "    # 10% of the time, we replace masked input tokens with random word\n",
        "    # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
        "\n",
        "    indices_replaced = np.random.binomial(n=1,p=0.8,size=labels.shape) * masked_indices\n",
        "\n",
        "    indices_random =  np.random.binomial(n=1,p=0.5,size=labels.shape) * masked_indices\n",
        "    indices_random =  np.maximum(indices_random - indices_replaced,0)\n",
        "\n",
        "    \n",
        "    #get list of feasible random word replacements\n",
        "    all_tokens = list(tokenizer.get_vocab().values())\n",
        "    normal_tokens = [t for t in all_tokens if t not in tokenizer.all_special_ids]\n",
        "      \n",
        "    random_words = np.random.choice(normal_tokens, size=labels.shape) * indices_random\n",
        "    #adjust inputs by removed selected existing tokens\n",
        "    indices_filter = 1 - (indices_replaced + indices_random)\n",
        "\n",
        "    inputs[\"input_ids\"] *= indices_filter\n",
        "    inputs[\"input_ids\"] += indices_replaced * tokenizer.mask_token_id\n",
        "    inputs[\"input_ids\"] += random_words\n",
        "  \n",
        "  else:\n",
        "    #in predict mode, replace all masked tokens with mask\n",
        "    indices_filter = 1 - masked_indices\n",
        "    inputs[\"input_ids\"] *= indices_filter\n",
        "    inputs[\"input_ids\"] += masked_indices * tokenizer.mask_token_id\n",
        "\n",
        "  return inputs, labels, masked_indices, df_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAbt5bieobWv"
      },
      "source": [
        "### TF Data transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNl1btbFKX61"
      },
      "source": [
        "def preprocess_data(df,\n",
        "                    train, \n",
        "                    task,  \n",
        "                    mask_strategy=None, \n",
        "                    analysis=None, \n",
        "                    repeat=1,\n",
        "                    show_masks=False, \n",
        "                    max_length=config[\"max_length\"], \n",
        "                    batch_size=config[\"batch_size\"], \n",
        "                    shuffle_batches=config[\"shuffle_batches\"], \n",
        "                    smart_batching=config[\"smart_batching\"],\n",
        "                    unpad=True): \n",
        "      \n",
        "        #Converts a dataframe into into a tokenized Tensorflow Dataset\n",
        "        #Batches are \"smart\" for speed based on http://mccormickml.com/2020/07/29/smart-batching-tutorial/\n",
        "\n",
        "        #used for rolling window shuffle, thus orignal size to not mix epochs too much\n",
        "        n_obs = len(df.index)\n",
        "\n",
        "        label_ids = None\n",
        "        #token prepending\n",
        "        if task in [\"augmentation\", \"spex\"]:\n",
        "          text, label_ids = prepend_labels(df, task)\n",
        "        else:\n",
        "          text = df.text\n",
        "\n",
        "        #Use the hugginface tokenizer to convert text into tokens and additional masks.\n",
        "        inputs = tokenizer(\n",
        "            text = text.values.tolist(),\n",
        "            text_pair = df.text_pair.values.tolist() if 'text_pair' in df.columns else None,\n",
        "            return_tensors=\"np\",\n",
        "            return_attention_mask=True,\n",
        "            return_token_type_ids=True,\n",
        "            return_special_tokens_mask=True,\n",
        "            max_length=max_length,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "        ).data\n",
        "\n",
        "        #task specific processing\n",
        "\n",
        "        if task == \"augmentation\":\n",
        "          inputs, labels, masked_indices, df_labels = augmentation_preprocessing(inputs, df, label_ids, train, mask_strategy, repeat, analysis)\n",
        "        elif task == \"spex\":\n",
        "           inputs, labels = spex_preprocessing(inputs, df, label_ids)\n",
        "        elif task == \"spanbert\":\n",
        "           inputs, labels = spanbert_preprocessing(inputs, df)\n",
        "        elif task == \"classification\":\n",
        "           inputs, labels = classification_preprocessing(inputs, df)\n",
        "        else:\n",
        "          raise Exception(\"Unknown task\")   \n",
        "\n",
        "        if show_masks:\n",
        "          print(\"decode inputs\")\n",
        "          decode_inputs(inputs)\n",
        "        \n",
        "        if train and smart_batching:\n",
        "          #order based on token length\n",
        "          order = inputs[\"attention_mask\"].sum(axis=1).argsort()\n",
        "          inputs = {key: inputs[key][order] for key in inputs.keys()}\n",
        "          labels = labels[order] \n",
        "\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(\n",
        "            (inputs, labels) if train else inputs\n",
        "        )\n",
        "\n",
        "        #Shuffle samples for randomness, if smart batching a small rolling window is used to keep roughly equal length in a batch.\n",
        "        if train:\n",
        "          buffer_size = min(shuffle_batches * batch_size, n_obs) if smart_batching else n_obs\n",
        "          \n",
        "          dataset = dataset.shuffle(\n",
        "              buffer_size=buffer_size,\n",
        "              reshuffle_each_iteration=True,\n",
        "              seed=1234,\n",
        "          )\n",
        "\n",
        "\n",
        "        dataset = dataset.batch(batch_size)\n",
        "\n",
        "        #Shuffle batches to randomize lengths.\n",
        "        if train:\n",
        "          dataset = dataset.shuffle(\n",
        "              np.ceil(n_obs / batch_size), reshuffle_each_iteration=True\n",
        "          )\n",
        "\n",
        "        #Unpad batches to the longest sequence in a batch for speed.\n",
        "        def unpad_batch(batch, labels=None):\n",
        "            batch_sequence_lengths = tf.math.reduce_sum(batch[\"attention_mask\"], axis=1)\n",
        "\n",
        "            max_batch_length = tf.reduce_max(batch_sequence_lengths)\n",
        "            for field in [\"input_ids\", \"token_type_ids\", \"attention_mask\"]:\n",
        "                batch[field] = batch[field][:, :max_batch_length]\n",
        "\n",
        "            if task in [\"spex\",\"augmentation\", \"spanbert\"] and train:\n",
        "              labels = labels[..., :max_batch_length]\n",
        "\n",
        "              if task == \"spanbert\":\n",
        "                batch[\"masked_indices\"] = batch[\"masked_indices\"][:, :max_batch_length]\n",
        "\n",
        "            return batch, labels\n",
        "\n",
        "        if unpad:\n",
        "          dataset = dataset.map(unpad_batch)\n",
        "\n",
        "        if task == \"augmentation\" and not train:\n",
        "          return dataset, inputs[\"input_ids\"], masked_indices, df_labels\n",
        "        elif task==\"spex\" and not train:\n",
        "          return dataset, labels\n",
        "        else:\n",
        "          return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqbItFXVJ8y2"
      },
      "source": [
        "# Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4c0cgu3Lc8n"
      },
      "source": [
        "### Model helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnYqe_ItWwxZ"
      },
      "source": [
        "def switch_head(old_model, task, summary=False, **kwargs):\n",
        "  model_config = BertConfig.from_pretrained(PRETRAINED_MODEL)\n",
        "  path = f\"models/cache/{secrets.token_hex(4)}\"\n",
        "  old_model.save_pretrained(path)\n",
        "  model_config.update(kwargs)\n",
        "  new_model = task.from_pretrained(path, config=model_config)\n",
        "\n",
        "  if summary:\n",
        "    new_model.summary()\n",
        "\n",
        "  return new_model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jObSKBXJ9ONW"
      },
      "source": [
        "from sklearn.metrics import  (\n",
        "    log_loss,\n",
        "    mean_squared_error,\n",
        "    mean_absolute_error,\n",
        "    median_absolute_error,\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    f1_score,\n",
        "    matthews_corrcoef,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    roc_auc_score,\n",
        ")\n",
        "\n",
        "def calculate_metrics(y_true, y_prob, prefix=False): \n",
        "  proba_metrics = {\n",
        "      \"Log Loss\": log_loss(y_true.round(), y_prob),\n",
        "      \"MSE\": mean_squared_error(y_true, y_prob),\n",
        "      \"MAE\": mean_absolute_error(y_true, y_prob),\n",
        "      \"MedianAE\": median_absolute_error(y_true, y_prob),\n",
        "  }\n",
        "\n",
        "  y_pred = y_prob.round()\n",
        "  y_true = y_true.round()\n",
        "\n",
        "  tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[False, True]).ravel()\n",
        "  binary_metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"Macro F1\": f1_score(y_true, y_pred, average=\"macro\"),\n",
        "        \"Matthews\": matthews_corrcoef(y_true, y_pred),\n",
        "        \"Precision\": precision_score(y_true, y_pred),\n",
        "        \"Recall\": recall_score(y_true, y_pred),\n",
        "        \"ROC AUC\": roc_auc_score(y_true, y_pred, average=\"macro\"),\n",
        "        \"Micro F1\": f1_score(y_true, y_pred, average=\"micro\"),\n",
        "        \"True Negatives\": tn,\n",
        "        \"True Positives\": tp,\n",
        "        \"False Positives\": fp,\n",
        "        \"False Negatives\": fn\n",
        "    }\n",
        "\n",
        "  combined = {**binary_metrics, **proba_metrics}\n",
        "\n",
        "  if prefix:\n",
        "    combined = {f\"{prefix} {key}\": val for key, val in combined.items()} \n",
        "\n",
        "  return combined\n",
        "\n",
        "def aggregate_metrics(results):\n",
        "  metrics_agg = {\n",
        "    \"n_runs\": len(results)\n",
        "  }\n",
        "\n",
        "  for metric in results[0].keys():\n",
        "    metric_rows = np.array([row[metric] for row in results])\n",
        "    metrics_agg[metric+\" (mean)\"] = metric_rows.mean()\n",
        "    metrics_agg[metric+\" (std)\"] = metric_rows.std()\n",
        "\n",
        "  return metrics_agg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGSeRfq26XEA"
      },
      "source": [
        "def flatten_metric(metric):\n",
        "    #check if metric has multiple values per class\n",
        "    #only case for matthews but is symmetric\n",
        "    if isinstance(metric, np.ndarray):\n",
        "      return metric[0].item()\n",
        "    else: \n",
        "      return metric\n",
        "\n",
        "class TrainLogger(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, task=\"\"):\n",
        "    self.task = task\n",
        "  \n",
        "  def on_train_end(self, logs=None):\n",
        "    wandb.run.summary[\"graph\"] = wandb.Graph.from_keras(self.model)\n",
        "\n",
        "  def on_train_batch_end(self, batch, logs=None):    \n",
        "    metrics = {f\"Train {key} ({self.task})\": flatten_metric(value) for key, value in logs.items()}\n",
        "    wandb.log(metrics, commit=True)\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    metrics = {f\"Epoch {key} ({self.task})\": flatten_metric(value) for key, value in logs.items()}\n",
        "    wandb.log(metrics, commit=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCJ2MrwQYXhI"
      },
      "source": [
        "#optimizers\n",
        "from tensorflow_addons.optimizers import LAMB\n",
        "from transformers import AdamWeightDecay\n",
        "\n",
        "from transformers.models.bert.modeling_tf_bert import TFBertPreTrainedModel, TFBertMainLayer, TFBertForMaskedLM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfvfXRSrstrA"
      },
      "source": [
        "### SpanBERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT4z0h9wniR6"
      },
      "source": [
        "from transformers.models.bert.modeling_tf_bert import TFBertPredictionHeadTransform, TFBertMLMHead, TFBertPositionEmbeddings\n",
        "\n",
        "class TFBertForSpanBert(TFBertForMaskedLM):\n",
        "  def __init__(self, config, *inputs, position_size=200,**kwargs):\n",
        "      super().__init__(config, *inputs, **kwargs)\n",
        "\n",
        "      self.sbo_hidden = TFBertPredictionHeadTransform(config, name=\"sbo_hidden\")\n",
        "      self.sbo = TFBertMLMHead(config, input_embeddings=self.bert.embeddings.word_embeddings, name=\"sbo___cls\")\n",
        "      \n",
        "      self.position_size = position_size\n",
        "\n",
        "      self.position_embeddings = TFBertPositionEmbeddings(\n",
        "            max_position_embeddings=config.max_position_embeddings,\n",
        "            hidden_size=position_size, # as per spanbert\n",
        "            initializer_range=config.initializer_range,\n",
        "            name=\"position_embeddings\",\n",
        "        )\n",
        "\n",
        "  def call(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None,\n",
        "        labels=None,\n",
        "        training=False,\n",
        "        **kwargs,\n",
        "    ):\n",
        "      inputs = input_processing(\n",
        "            func=self.call,\n",
        "            config=self.config,\n",
        "            input_ids=input_ids[\"input_ids\"],\n",
        "            attention_mask=input_ids.get(\"attention_mask\"),\n",
        "            token_type_ids=input_ids.get(\"token_type_ids\"),\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "            labels=labels,\n",
        "            training=training,\n",
        "            kwargs_call=kwargs,\n",
        "        )\n",
        "    \n",
        "      outputs = self.bert(\n",
        "            input_ids=inputs[\"input_ids\"],\n",
        "            attention_mask=inputs[\"attention_mask\"],\n",
        "            token_type_ids=inputs[\"token_type_ids\"],\n",
        "            position_ids=inputs[\"position_ids\"],\n",
        "            head_mask=inputs[\"head_mask\"],\n",
        "            inputs_embeds=inputs[\"inputs_embeds\"],\n",
        "            output_attentions=inputs[\"output_attentions\"],\n",
        "            output_hidden_states=inputs[\"output_hidden_states\"],\n",
        "            return_dict=inputs[\"return_dict\"],\n",
        "            training=inputs[\"training\"],\n",
        "        )\n",
        "      sequence_output = outputs[0]\n",
        "\n",
        "      if input_ids.get(\"masked_indices\") is not None:\n",
        "        #mlm\n",
        "        masked_sequence_output = tf.boolean_mask(sequence_output, input_ids[\"masked_indices\"])\n",
        "        masked_sequence_output = tf.expand_dims(masked_sequence_output, axis=0)\n",
        "        \n",
        "        mlm_preds = self.mlm(sequence_output=masked_sequence_output, training=inputs[\"training\"])[0]\n",
        "        \n",
        "        #sbo\n",
        "        span_lengths = tf.reduce_sum(input_ids[\"masked_indices\"], axis=-1)\n",
        "        \n",
        "        #get indices for gather: \n",
        "        # if span_lengths [3,1,2]\n",
        "        #position relative from start [0,1,2,0,0,1]\n",
        "        #hidden state repeats indices to get hidden state * span_lengths [0,0,0,1,2,2]\n",
        "        \n",
        "        position_indices = tf.ragged.range(span_lengths).flat_values\n",
        "        hidden_repeats = tf.repeat(tf.range(len(span_lengths)), span_lengths)\n",
        "\n",
        "        #get left and right hidden states \n",
        "        #[hidden_state x obs]\n",
        "        left_indices, right_indices = tf.unstack(input_ids[\"pair_indices\"], axis=1)\n",
        "        left_hidden = tf.gather(sequence_output, left_indices, batch_dims=1)\n",
        "        right_hidden = tf.gather(sequence_output, right_indices, batch_dims=1)\n",
        "\n",
        "        # [n_masked_tokens x hidden_size]\n",
        "        left_hidden = tf.gather(left_hidden, hidden_repeats)\n",
        "        right_hidden = tf.gather(right_hidden, hidden_repeats)\n",
        "\n",
        "        # [max_span_length x hidden_size]\n",
        "        max_span_length = tf.math.reduce_max(span_lengths)\n",
        "        position_embeds = self.position_embeddings(sequence_output[:1, :max_span_length,:self.position_size])[0]\n",
        "        # [n_masked_tokens x hidden_size] \n",
        "        position_hidden = tf.gather(position_embeds, position_indices)\n",
        "\n",
        "        #combine the three inputs into a single vector of size [n_masked_tokens x 2*hidden_size + position_size]\n",
        "        sbo_sequence = tf.concat([left_hidden, right_hidden, position_hidden], axis=1)\n",
        "        #apply compression dense layer to [n_masked_tokens x hidden_size] \n",
        "        sbo_output = self.sbo_hidden(hidden_states=sbo_sequence,  training=inputs[\"training\"])\n",
        "\n",
        "        #Apply second layer and map to tokens, extra dim is needed for input [1 x n_masked_tokens x hidden_size] \n",
        "        sbo_output = tf.expand_dims(sbo_output, axis=0)\n",
        "        sbo_preds = self.sbo(sequence_output=sbo_output, training=inputs[\"training\"])[0] #remove dim again\n",
        "        \n",
        "        #stack both preds [n_masked_tokens x 2 (tasks) x hidden_size] \n",
        "        combined_preds = tf.stack([mlm_preds, sbo_preds], axis=1)\n",
        "        \n",
        "        return combined_preds\n",
        "      else:\n",
        "        return sequence_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlduQu0cKDxs"
      },
      "source": [
        "scce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
        "def spanbert_loss(y_true, y_pred):\n",
        "    mlm_preds, sbo_preds = tf.unstack(y_pred, axis=1)\n",
        "    y_true_masked = tf.boolean_mask(y_true, tf.not_equal(y_true, -100))\n",
        "    mlm_loss = scce(y_true_masked, mlm_preds)\n",
        "    sbo_loss = scce(y_true_masked, sbo_preds)\n",
        "    loss = mlm_loss + sbo_loss\n",
        "    return loss \n",
        "\n",
        "def spanbert_training(train_df, dev_df, model):\n",
        "\n",
        "  train_dataset = preprocess_data(train_df, \n",
        "                            train=True,\n",
        "                            task=\"spanbert\")\n",
        "  \n",
        "  dev_dataset = preprocess_data(dev_df, \n",
        "                            train=True,\n",
        "                            task=\"spanbert\")\n",
        "\n",
        "  # model = switch_head(model, TFBertForSpanBert)\n",
        "\n",
        "  optimizer = LAMB(learning_rate=config[\"optimizer_lr\"], epsilon=config[\"optimizer_epsilon\"])\n",
        "  loss  = spanbert_loss\n",
        "\n",
        "  tf.keras.backend.clear_session()\n",
        "  model.compile(optimizer, loss)\n",
        "\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(restore_best_weights=True)\n",
        "\n",
        "  model.fit(train_dataset,\n",
        "            validation_data=dev_dataset, \n",
        "            epochs=config[\"sb_epochs\"], \n",
        "            callbacks=[TrainLogger(task=\"SpanBERT\"), early_stopping]\n",
        "            )\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOqZ1_TPjxWb"
      },
      "source": [
        "import os.path\n",
        "from os import path\n",
        "\n",
        "def from_spanbert(train_df=None, dev_df=None):\n",
        "  base_path = \"/content/drive/Shareddrives/Thesis/models/spanbert/\"\n",
        "  model_name_cols = [\"dataset\",\"max_length\", \"n_spanbert_repeat\",\"span_clip_multiplier\",\"sb_epochs\"]\n",
        "  model_name = \" - \".join([f\"{col} {config[col]}\" for col in model_name_cols])\n",
        "  print(f\"checking for spanbert model: {model_name}\")\n",
        "\n",
        "  full_path = base_path + model_name\n",
        "  \n",
        "  if path.exists(full_path):\n",
        "    print(\"Retrieving SpanBERT model from cache\")\n",
        "    model_config = BertConfig.from_pretrained(PRETRAINED_MODEL)\n",
        "    model = TFBertForSpanBert.from_pretrained(full_path, config=model_config)\n",
        "  else:\n",
        "    if train_df is None or dev_df is None:\n",
        "      raise Exception(\"Spanbert Model needs to be trained but no datasets provided\")\n",
        "    print(\"Training new SpanBERT model\")\n",
        "    model = TFBertForSpanBert.from_pretrained(PRETRAINED_MODEL)\n",
        "    model = spanbert_training(train_df, dev_df, model)\n",
        "    model.save_pretrained(full_path)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcFgeT8Xsz3d"
      },
      "source": [
        "### Span Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zNrgR3eLX3E"
      },
      "source": [
        "Simulating weak supervision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2IcjYvlX8QK"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set_theme()\n",
        "def simulate_ws(df):\n",
        "  mu, var = config[\"ws_mean\"], config[\"ws_var\"]\n",
        "\n",
        "  if mu < 0.5 or var >= mu * (1-mu):\n",
        "    raise Exception(\"Invalid mu or variance provided\")\n",
        "  \n",
        "  alpha = ((1-mu)/var - 1/mu) * (mu ** 2) \n",
        "  beta = alpha*(1/mu - 1)\n",
        "\n",
        "  draws = np.random.beta(alpha, beta, size=len(df.index))\n",
        "\n",
        "  #log draws\n",
        "  table_title = f'Weak Supervison draws'\n",
        "  if config[\"ws_histogram\"]:\n",
        "    plt = sns.distplot(draws, axlabel=table_title)\n",
        "    \n",
        "  table = wandb.Table(data=[[d] for d in draws], columns=[\"draws\"])\n",
        "  wandb.log({table_title: wandb.plot.histogram(table, \"draws\", title=table_title)})\n",
        "\n",
        "  y_true = df.label.values\n",
        "  y_weak = np.absolute(y_true - (1-draws))\n",
        "\n",
        "\n",
        "  metrics = calculate_metrics(y_true, y_weak, prefix=\"WS\")\n",
        "  wandb.log(metrics)\n",
        "\n",
        "  if config[\"ws_metrics\"]:\n",
        "    print(\"Weak Supervision metrics\")\n",
        "    display(metrics)\n",
        "\n",
        "  df.label = y_weak\n",
        "\n",
        "  return df, metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BGdrre7uzfC"
      },
      "source": [
        "Token selection model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nI1X3xunYL4"
      },
      "source": [
        "from transformers import TFBertForQuestionAnswering\n",
        "from transformers.modeling_tf_utils import input_processing\n",
        "class TFBertForSpanSelection(TFBertForQuestionAnswering):       \n",
        "  def call(\n",
        "        self,\n",
        "        input_ids = None,\n",
        "        attention_mask = None,\n",
        "        token_type_ids = None,\n",
        "        position_ids = None,\n",
        "        head_mask = None,\n",
        "        inputs_embeds = None,\n",
        "        output_attentions = None,\n",
        "        output_hidden_states = None,\n",
        "        return_dict = None,\n",
        "        start_positions = None,\n",
        "        end_positions = None,\n",
        "        training = False,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        calc_attentions = not training and self.run_eagerly\n",
        "\n",
        "        inputs = input_processing(\n",
        "            func=self.call,\n",
        "            config=self.config,\n",
        "            input_ids=input_ids[\"input_ids\"],\n",
        "            attention_mask= input_ids.get(\"attention_mask\"),\n",
        "            token_type_ids=input_ids.get(\"token_type_ids\"),\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=calc_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "            start_positions=start_positions,\n",
        "            end_positions=end_positions,\n",
        "            training=training,\n",
        "            kwargs_call=kwargs,\n",
        "        )\n",
        "\n",
        "        outputs = self.bert(\n",
        "            input_ids=inputs[\"input_ids\"],\n",
        "            attention_mask=inputs[\"attention_mask\"],\n",
        "            token_type_ids=inputs[\"token_type_ids\"],\n",
        "            position_ids=inputs[\"position_ids\"],\n",
        "            head_mask=inputs[\"head_mask\"],\n",
        "            inputs_embeds=inputs[\"inputs_embeds\"],\n",
        "            output_attentions=inputs[\"output_attentions\"],\n",
        "            output_hidden_states=inputs[\"output_hidden_states\"],\n",
        "            return_dict=inputs[\"return_dict\"],\n",
        "            training=inputs[\"training\"],\n",
        "        )\n",
        "        sequence_output = outputs[0]\n",
        "        logits = self.qa_outputs(inputs=sequence_output)\n",
        "        splits = tf.split(value=logits, num_or_size_splits=self.num_labels , axis=-1)\n",
        "        squeezed = [tf.squeeze(input=s, axis=-1) for s in splits]\n",
        "\n",
        "        if len(squeezed) == 1:\n",
        "          predictions = squeezed[0]\n",
        "        else:\n",
        "          predictions = tf.stack(squeezed, axis=1)\n",
        "\n",
        "\n",
        "        if calc_attentions:\n",
        "          #if span modeee\n",
        "\n",
        "          # #stack layer attentions\n",
        "          # attentions = tf.stack(outputs[\"attentions\"], axis=0)\n",
        "\n",
        "          # #mean per layer\n",
        "          # attentions = tf.math.reduce_mean(attentions, axis=0)\n",
        "\n",
        "          #get attentions from last layer\n",
        "          # print(outputs[\"attentions\"][:10])\n",
        "          attentions = outputs[\"attentions\"][-1]\n",
        "\n",
        "          #mean per head\n",
        "          attentions = tf.math.reduce_mean(attentions, axis=1)\n",
        "\n",
        "          #mean per token\n",
        "          attentions = tf.math.reduce_mean(attentions, axis=1)\n",
        "          \n",
        "          return predictions, attentions\n",
        "        else:\n",
        "          return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_Mmez6l-hNG"
      },
      "source": [
        "cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "def span_selection_loss(labels, logits):\n",
        "  loss = cce(labels, logits)\n",
        "  if config[\"spex_mode\"] == \"span\":\n",
        "    #If multiple tasks, reduce loss per task\n",
        "    loss = tf.math.reduce_mean(loss, axis=1)\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jiedAhUKHUS"
      },
      "source": [
        "def spex_training(train_df,  dev_df, model, log_name, epochs=1):\n",
        "  print(f\"\\nSpan Extraction {log_name} training\\n\")\n",
        "  if config[\"spex_mode\"] == \"token\":\n",
        "     model = switch_head(model, TFBertForSpanSelection, num_labels=1) \n",
        "  else:\n",
        "     model = switch_head(model, TFBertForSpanSelection, num_labels=2) \n",
        "  \n",
        "  train_dataset = preprocess_data(df=train_df, train=True, task=\"spex\")\n",
        "  dev_dataset = preprocess_data(df=dev_df, train=True, task=\"spex\")                          \n",
        "  \n",
        "  loss = span_selection_loss\n",
        "  optimizer = LAMB(learning_rate=config[\"optimizer_lr\"], epsilon=config[\"optimizer_epsilon\"])\n",
        "  train_metrics = [\n",
        "      tf.keras.metrics.CategoricalAccuracy(name=\"Accuracy\")\n",
        "    ]\n",
        "  \n",
        "  tf.keras.backend.clear_session()\n",
        "  model.compile(optimizer, span_selection_loss, train_metrics)\n",
        "  \n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(restore_best_weights=True)\n",
        "\n",
        "  log_name = \"ExEval \"+prefix if prefix else \"ExEval\" \n",
        "  model.fit(train_dataset,\n",
        "            validation_data=dev_dataset, \n",
        "            epochs=epochs, \n",
        "            callbacks=[TrainLogger(task=\"spex\"+log_name), early_stopping]\n",
        "            )\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpCia3NTLYYK"
      },
      "source": [
        "def target_analysis(df, model):\n",
        "  print(\"\\nTarget Analysis\\n\")\n",
        "  if config[\"spex_mode\"] == \"token\":\n",
        "     model = switch_head(model, TFBertForSpanSelection, num_labels=1) \n",
        "  else:\n",
        "     model = switch_head(model, TFBertForSpanSelection, num_labels=2) \n",
        "  \n",
        "  dataset, labels = preprocess_data(df=df, \n",
        "                            train=False,\n",
        "                            task=\"spex\",\n",
        "                            unpad=False\n",
        "                            )\n",
        "  \n",
        "  model.compile(run_eagerly=True)\n",
        "\n",
        "  predictions, attentions = model.predict(dataset)\n",
        "\n",
        "  probs = softmax(predictions, axis=-1)\n",
        "  complexity = 1 - (probs * labels).sum(axis=-1)\n",
        "\n",
        "  if config[\"spex_mode\"] == \"span\":\n",
        "    complexity = complexity.mean(axis=1)\n",
        "\n",
        "  return complexity, attentions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8dj6s3Os3yN"
      },
      "source": [
        "### Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO-pXQ-0nw42"
      },
      "source": [
        "# ONLY USED FOR TARGET AUGMENTATION NOT TRAINING\n",
        "class TFBertForPredictMaskedLM(TFBertForMaskedLM):\n",
        "  def call(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None,\n",
        "        labels=None,\n",
        "        training=False,\n",
        "        **kwargs,\n",
        "    ):\n",
        "\n",
        "    outputs = super().call( \n",
        "        input_ids[\"input_ids\"],\n",
        "        input_ids.get(\"attention_mask\"),\n",
        "        input_ids.get(\"token_type_ids\"),\n",
        "        position_ids,\n",
        "        head_mask,\n",
        "        inputs_embeds,\n",
        "        output_attentions,\n",
        "        output_hidden_states,\n",
        "        return_dict,\n",
        "        labels,\n",
        "        training\n",
        "    )\n",
        "\n",
        "    # print(outputs)\n",
        "\n",
        "    if training or not self.run_eagerly:\n",
        "      return outputs\n",
        "    else:  \n",
        "      probs = tf.nn.softmax(outputs.logits, axis=2)\n",
        "\n",
        "      complexity = input_ids.get(\"complexity\")\n",
        "      if config[\"augmentation\"] == \"hetero\" and complexity is not None: \n",
        "        #observation specific lower bounds\n",
        "        obs_lower_bounds = config[\"LB\"] + (config[\"UB\"]  - config[\"LB\"])*complexity\n",
        "\n",
        "        sorted_probs = tf.sort(probs, direction='DESCENDING')\n",
        "        sorted_indices = tf.argsort(probs, direction='DESCENDING')\n",
        "        cum_prob = tf.math.cumsum(sorted_probs, axis=-1)\n",
        "\n",
        "        ub_mask = tf.math.greater_equal(cum_prob, 1-config[\"UB\"])\n",
        "        \n",
        "        lb_threshold = tf.stack([tf.fill(tf.shape(ub_mask[0]), 1 - lb) for lb in obs_lower_bounds], axis=0)\n",
        "        lb_mask = tf.math.less_equal(cum_prob, lb_threshold)\n",
        "\n",
        "        prob_mask = tf.math.logical_and(ub_mask, lb_mask)\n",
        "        prob_mask = tf.cast(prob_mask, tf.float32)\n",
        "        \n",
        "        n_viable_tokens = tf.math.reduce_sum(prob_mask, axis=-1)\n",
        "        mean_viable_tokens = tf.math.reduce_mean(n_viable_tokens).numpy()\n",
        "        \n",
        "        if mean_viable_tokens < 10:\n",
        "          print(f\"Mean suitable candidate tokens: {mean_viable_tokens.round(2)}\")\n",
        "          print(f\"Mean complexity: {tf.math.reduce_mean(complexity).numpy()}\")\n",
        "\n",
        "        if tf.math.reduce_min(n_viable_tokens).numpy() == 0:\n",
        "          # if no viable tokens, set most likely token to prob 1\n",
        "          backup_mask = 1-tf.math.minimum(n_viable_tokens, 1)\n",
        "          backup_mask = tf.expand_dims(backup_mask, axis=2)\n",
        "          paddings = [[0,0], [0,0],[0, tf.shape(prob_mask)[-1] -1]]\n",
        "          backup_mask = tf.pad(backup_mask, paddings)\n",
        "          prob_mask+= backup_mask\n",
        "\n",
        "          print(\"No candidate tokens for an observation\")\n",
        "          print(f\"Mean suitable candidate tokens: {mean_viable_tokens.round(2)}\")\n",
        "        \n",
        "       \n",
        "        #filter out of bounds candidates\n",
        "        candidate_probs = sorted_probs * prob_mask\n",
        "\n",
        "        #reweight probabilities\n",
        "        candidate_probs /= tf.expand_dims(tf.reduce_sum(candidate_probs, axis=-1), axis=-1) \n",
        "        candiate_logits = tf.math.log(candidate_probs)\n",
        "\n",
        "        #sample tokens\n",
        "\n",
        "        sampled_indices = tf.stack([tf.random.categorical(l, 1) for l in candiate_logits], axis=0)\n",
        "        sampled_indices = tf.squeeze(sampled_indices)\n",
        "        \n",
        "        preds = tf.gather(sorted_indices, sampled_indices, axis=2, batch_dims=2)\n",
        "        selected_probs = tf.gather(sorted_probs, sampled_indices, axis=2, batch_dims=2)\n",
        "\n",
        "      else:\n",
        "        #most likely selections\n",
        "        preds = tf.math.argmax(probs, axis=2)\n",
        "        selected_probs = tf.math.reduce_max(probs, axis=2)\n",
        "\n",
        "      #pad to equal batch length\n",
        "\n",
        "      shape = tf.shape(input_ids[\"input_ids\"])\n",
        "      paddings = [[0, 0], [0, config[\"max_length\"]-shape[1]]]\n",
        "      preds = tf.pad(preds, \n",
        "                    paddings, \n",
        "                    'CONSTANT', \n",
        "                    constant_values=tokenizer.pad_token_id)\n",
        "      \n",
        "      selected_probs = tf.pad(selected_probs, \n",
        "                    paddings, \n",
        "                    'CONSTANT', \n",
        "                    constant_values=0)\n",
        "      outputs.logits = preds\n",
        "      outputs.attentions = selected_probs\n",
        "\n",
        "      return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOupLwoGrFOv"
      },
      "source": [
        "scce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
        "def masked_sparse_categorical_crossentropy(y_true, y_pred):\n",
        "\n",
        "    y_true_masked = tf.boolean_mask(y_true, tf.not_equal(y_true, -100))\n",
        "    y_pred_masked = tf.boolean_mask(y_pred, tf.not_equal(y_true, -100))\n",
        "    loss = scce(y_true_masked, y_pred_masked)\n",
        "    return loss\n",
        "\n",
        "def augmentation_training(target_df, dev_df, model, logname=\"\"):\n",
        "  print(\"Augmentation training\")\n",
        "  train_dataset = preprocess_data(target_df, \n",
        "                            train=True,\n",
        "                            task=\"augmentation\",\n",
        "                            mask_strategy=\"base\",\n",
        "                            repeat=config[\"n_train_aug\"]\n",
        "                            )\n",
        "  \n",
        "  dev_dataset = preprocess_data(dev_df, \n",
        "                            train=True,\n",
        "                            task=\"augmentation\",\n",
        "                            mask_strategy=\"base\",\n",
        "                            repeat=config[\"n_train_aug\"]\n",
        "                            )\n",
        "\n",
        "  # model = switch_head(model, TFBertForMaskedLM)\n",
        "  model = switch_head(model, TFBertForPredictMaskedLM)\n",
        "\n",
        "  optimizer = LAMB(learning_rate=config[\"optimizer_lr\"], epsilon=config[\"optimizer_epsilon\"])\n",
        "  loss = masked_sparse_categorical_crossentropy\n",
        "\n",
        "  tf.keras.backend.clear_session()\n",
        "  model.compile(optimizer, loss)\n",
        "  \n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(restore_best_weights=True)\n",
        "\n",
        "  model.fit(train_dataset,\n",
        "            validation_data=dev_dataset, \n",
        "            epochs=config[\"aug_epochs\"], \n",
        "            callbacks=[TrainLogger(task=logname+ \" - aug\"), early_stopping]\n",
        "            )\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8Mdh4LD0pPk"
      },
      "source": [
        "from transformers import BertConfig\n",
        "\n",
        "def target_augmentation(target_df, model, analysis=None, mask_strategy=config[\"augmentation\"], prob_labels=config[\"probabilistic_labels\"], batch_size=config[\"batch_size\"], prefix=\"\", head=False):\n",
        "  print(\"Target Augmentation\")\n",
        "  dataset, input_ids, masked_indices, df_labels = preprocess_data(\n",
        "                            df=target_df, \n",
        "                            train=False,\n",
        "                            task=\"augmentation\",\n",
        "                            analysis=analysis,\n",
        "                            mask_strategy=mask_strategy,\n",
        "                            batch_size=batch_size,\n",
        "                            repeat=config[\"n_target_aug\"]\n",
        "                            )\n",
        "  \n",
        "  model = switch_head(model, TFBertForPredictMaskedLM, output_attentions=True)\n",
        "  \n",
        "  #Perform augmentation\n",
        "  tf.keras.backend.clear_session()\n",
        "  model.compile(run_eagerly=True)\n",
        "  predictions = model.predict(dataset, verbose=1)\n",
        "\n",
        "  preds = predictions.logits\n",
        "  probs = predictions.attentions\n",
        "  \n",
        "  #cut predictions to max sequence length\n",
        "  max_length = masked_indices.shape[1]\n",
        "  preds = preds[:,:max_length]\n",
        "  probs = probs[:,:max_length]\n",
        "\n",
        "  # place token predictions\n",
        "  inputs_masked = input_ids * (1 - masked_indices)\n",
        "  prediction_mask = preds * masked_indices\n",
        "  inputs_masked += prediction_mask\n",
        "  texts = tokenizer.batch_decode(inputs_masked)\n",
        "\n",
        "  #fill augmented df\n",
        "  def text_mapping(text, label):\n",
        "    start = len(f\"[CLS] {label_names[label]}\")\n",
        "    end = text.find(\"[SEP]\")\n",
        "    return text[start:end].strip()\n",
        "\n",
        "  def text_pair_mapping(text):\n",
        "    start =  text.find(\"[SEP]\")+len(\"[SEP]\")\n",
        "    end = text.find(\"[SEP]\", start)\n",
        "    return text[start:end].strip()\n",
        "\n",
        "  text = [text_mapping(text, df_labels[i]) for i,text in enumerate(texts)]\n",
        "  \n",
        "  if 'text_pair' in target_df.columns:\n",
        "    text_pair = [text_pair_mapping(text) for text in texts]\n",
        "  else:\n",
        "    text_pair = False\n",
        "\n",
        "  #calculate weak labels\n",
        "  if prob_labels:\n",
        "    probs_sum = np.sum(probs * masked_indices, axis=1)\n",
        "    K = masked_indices.sum(axis=1)\n",
        "\n",
        "    normal_mask = ~np.any([input_ids == t for t in tokenizer.all_special_ids], axis=0)\n",
        "    N = normal_mask.sum(axis=1) + K\n",
        "\n",
        "    if config[\"label_type\"] == \"natural\":\n",
        "      label_lengths = [len(l_ids) for l_ids in tokenizer(label_names, add_special_tokens=False).input_ids]\n",
        "      N -= np.array([label_lengths[label] for label in df_labels])\n",
        "\n",
        "    #formula\n",
        "    ##confidence = (np.square(N-K) + K * probs_sum) / np.square(N)\n",
        "    confidence = ((N-K) + probs_sum) / N\n",
        "\n",
        "    #insure no negative labels\n",
        "    confidence = np.fmax(confidence, config[\"min_weak_prob\"])\n",
        "\n",
        "    #set probabilistic labels\n",
        "    df_labels = np.absolute(1-df_labels-confidence)\n",
        "\n",
        "  #Save to df\n",
        "  augmented_df = pd.DataFrame({\"text\":text, \"label\":df_labels})\n",
        "\n",
        "  if text_pair is not False:\n",
        "    augmented_df[\"text_pair\"] = text_pair\n",
        "\n",
        "  #calculate diversity\n",
        "  n_unique_tokens = len(np.unique(prediction_mask)) - 1 #remove 0 \n",
        "  n_masked_tokens = masked_indices.sum()\n",
        "\n",
        "  type_token_ratio = {\n",
        "      prefix+\" Type Token Ratio\": n_unique_tokens / n_masked_tokens\n",
        "  }\n",
        "  wandb.log(type_token_ratio)\n",
        "  \n",
        "\n",
        "  #print some augmentations\n",
        "  if head:\n",
        "    print(\"\\nraw predictions\\n\")\n",
        "    texts = tokenizer.batch_decode(preds[:head])\n",
        "    for row in texts:\n",
        "      print(row.replace(\" [PAD]\", \"\"))\n",
        "\n",
        "    print(\"\\ninputs\\n\")\n",
        "    texts = tokenizer.batch_decode(input_ids[:head])\n",
        "    for row in texts:\n",
        "      print(row.replace(\" [PAD]\", \"\"))\n",
        "\n",
        "    print(\"\\nAugmented sequences\\n\")\n",
        "    texts = tokenizer.batch_decode(inputs_masked[:head])\n",
        "    for row in texts:\n",
        "      print(row.replace(\" [PAD]\", \"\"))\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "    display(target_df.head(head))\n",
        "    display(augmented_df.head(head))\n",
        "\n",
        "  return augmented_df, type_token_ratio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvZjC1wbJbc7"
      },
      "source": [
        "# Evaluation methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BFSdOqzmOTM"
      },
      "source": [
        "from transformers import TFBertForSequenceClassification\n",
        "#use to ensure attention mask and token type ids is used\n",
        "class TFBertForClassification(TFBertForSequenceClassification):\n",
        "  def call(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None,\n",
        "        labels=None,\n",
        "        training=False,\n",
        "        **kwargs,\n",
        "    ):\n",
        "\n",
        "    return super().call( \n",
        "        input_ids[\"input_ids\"],\n",
        "        input_ids.get(\"attention_mask\"),\n",
        "        input_ids.get(\"token_type_ids\"),\n",
        "        position_ids,\n",
        "        head_mask,\n",
        "        inputs_embeds,\n",
        "        output_attentions,\n",
        "        output_hidden_states,\n",
        "        return_dict,\n",
        "        labels,\n",
        "        training\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjtZG2Br1CW6"
      },
      "source": [
        "from tensorflow_addons.metrics import MatthewsCorrelationCoefficient, F1Score\n",
        "from scipy.special import softmax\n",
        "\n",
        "def extrinsic_evaluation(train_df, test_df, dev_df, epochs=config[\"extrinsic_epochs\"], model=None, finetune=False, prefix=False, patience=0, batch_size=config[\"extrinsic_batch_size\"]):\n",
        "  if finetune:\n",
        "    print(\"Finetuning Augmentation model\")\n",
        "    #Check if this doesnt mess with the global model\n",
        "    model = switch_head(model, TFBertForClassification)\n",
        "  else:\n",
        "    print(\"Training new end model\")\n",
        "    model = TFBertForClassification.from_pretrained(PRETRAINED_MODEL)\n",
        "\n",
        "  optimizer = LAMB(learning_rate=config[\"optimizer_lr\"], epsilon=config[\"optimizer_epsilon\"])\n",
        "  loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "  train_metrics = [\n",
        "      tf.keras.metrics.CategoricalAccuracy(name= \"Accuracy\"),\n",
        "      F1Score(num_classes=2, name=\"Micro F1\", average=\"micro\"),\n",
        "    ]\n",
        "\n",
        "  tf.keras.backend.clear_session()\n",
        "\n",
        "  model.compile(optimizer, loss, train_metrics)\n",
        "  \n",
        "  train_dataset = preprocess_data(train_df, train=True, task=\"classification\", batch_size=batch_size)\n",
        "  dev_dataset = preprocess_data(dev_df, train=True, task=\"classification\")\n",
        "  test_dataset = preprocess_data(test_df, train=False, task=\"classification\")\n",
        "  \n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_Accuracy\", \n",
        "                                                    mode=\"max\",\n",
        "                                                    patience=patience,\n",
        "                                                    restore_best_weights=True)\n",
        "\n",
        "  log_name = prefix+\" ExEval\" if prefix else \"ExEval\" \n",
        "  model.fit(train_dataset, \n",
        "            epochs=epochs,\n",
        "            validation_data=dev_dataset, \n",
        "            callbacks=[TrainLogger(task=log_name), early_stopping])\n",
        "\n",
        "  predictions = model.predict(test_dataset)[0]\n",
        "  y_probs = softmax(predictions, axis=1)\n",
        "  y_pred = np.argmax(predictions, axis=1)\n",
        "  y_true = test_df.label.values\n",
        "\n",
        "  metrics = calculate_metrics(y_true, y_pred, prefix=prefix)\n",
        "\n",
        "  wandb.log({prefix+\" pr\" : wandb.plot.pr_curve(y_true, y_probs, labels=class_names),\n",
        "             prefix+\" roc\" : wandb.plot.roc_curve(y_true, y_probs, labels=class_names),\n",
        "             prefix+\" conf_mat\" : wandb.plot.confusion_matrix(y_probs, y_true, class_names=class_names)})\n",
        "\n",
        "  wandb.log(metrics)\n",
        "  return metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F8tmIOT3cCu"
      },
      "source": [
        "def train_eval_model(train_df, dev_df, test_df, epochs=config[\"eval_epochs\"], batch_size=config[\"eval_batch_size\"]):\n",
        "  print(\"Training Eval model\")\n",
        "  eval_model = TFBertForClassification.from_pretrained(PRETRAINED_MODEL)\n",
        "  \n",
        "  optimizer = LAMB(learning_rate=config[\"optimizer_lr\"], epsilon=config[\"optimizer_epsilon\"])\n",
        "  loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "  train_metrics = [\n",
        "      tf.keras.metrics.CategoricalAccuracy(name= \"Accuracy\")\n",
        "    ]\n",
        "\n",
        "  tf.keras.backend.clear_session()\n",
        "\n",
        "  eval_model.compile(optimizer, loss, train_metrics)\n",
        "\n",
        "  train_dataset = preprocess_data(train_df, train=True, task=\"classification\", batch_size=batch_size)\n",
        "  dev_dataset = preprocess_data(dev_df, train=True, task=\"classification\", batch_size=batch_size)\n",
        "\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(restore_best_weights=True)\n",
        "\n",
        "  eval_model.fit(train_dataset,\n",
        "                 validation_data=dev_dataset, \n",
        "                 epochs=epochs, \n",
        "                 callbacks=[TrainLogger(task=\"Semantic\"), early_stopping])\n",
        "  \n",
        "  test_dataset = preprocess_data(test_df, train=False, task=\"classification\", batch_size=batch_size)\n",
        "\n",
        "  predictions = eval_model.predict(test_dataset)[0]\n",
        "  y_probs = softmax(predictions, axis=1)\n",
        "  y_pred = np.argmax(predictions, axis=1)\n",
        "  y_true = test_df.label.values\n",
        "\n",
        "  semantic_metrics = calculate_metrics(y_true, y_pred, prefix=\"Semantic\")\n",
        "\n",
        "  wandb.log({\"Semantic pr\" : wandb.plot.pr_curve(y_true, y_probs, labels=class_names),\n",
        "             \"Semantic roc\" : wandb.plot.roc_curve(y_true, y_probs, labels=class_names),\n",
        "             \"Semantic conf_mat\" : wandb.plot.confusion_matrix(y_probs, y_true, class_names=class_names)})\n",
        "\n",
        "  wandb.log(semantic_metrics)\n",
        "\n",
        "  return eval_model, semantic_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jpB7LXB3Wko"
      },
      "source": [
        "def semantic_eval(eval_model, augmented_df, prefix=\"\"):\n",
        "  print(\"Semantic evaluation \"+prefix)\n",
        "  dataset = preprocess_data(augmented_df, train=False, task=\"classification\")\n",
        "\n",
        "  # in this case predictions serve as ground truth to evaluate weak labels\n",
        "  predictions = eval_model.predict(dataset)[0]\n",
        "\n",
        "  y_probs = softmax(predictions, axis=1)\n",
        "  y_true = y_probs[:,1]\n",
        "\n",
        "  y_weak = augmented_df.label.values\n",
        "\n",
        "  logname = prefix+ \" sem_eval\"\n",
        "  metrics = calculate_metrics(y_true, y_weak, prefix=logname)\n",
        "  wandb.log(metrics)\n",
        "\n",
        "  return metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSGyM5Hwu6BG"
      },
      "source": [
        "def augmentation_eval(target_df, augmented_df, test_data, dev_df, model=None, prefix=\"eval\"):\n",
        "  print(\"Extrinsic Evaluation\")\n",
        "\n",
        "  metrics = {}\n",
        "\n",
        "  # print(\"only augmented data\")\n",
        "  # only_aug_metrics = extrinsic_evaluation(augmented_df, test_data, dev_df, finetune=False, prefix=f\"{prefix} - Only AUG\")\n",
        "  # metrics.update(only_aug_metrics)\n",
        "\n",
        "  # print(\"only target but equal amount of data as combined\")\n",
        "  # only_target_more_data = extrinsic_evaluation(target_df, test_data, dev_df, finetune=False, prefix=f\"{prefix} - Only Target\", epochs=config[\"extrinsic_epochs\"] * (config[\"n_target_aug\"] + 1))\n",
        "  # metrics.update(only_target_more_data)\n",
        "  \n",
        "  print(\"Combined dataset\")\n",
        "  combined_df = pd.concat([target_df, augmented_df], ignore_index=True)\n",
        "  combined_metrics = extrinsic_evaluation(combined_df, test_data, dev_df, finetune=False, prefix=f\"{prefix} - Combined\")\n",
        "  metrics.update(combined_metrics)\n",
        "\n",
        "  if model is not None:\n",
        "    print(\"Combined dataset with finetuned model\")\n",
        "    combined_wam = extrinsic_evaluation(combined_df, test_data, dev_df, finetune=True, model=model, prefix=f\"{prefix} - Combined wAM\", patience=2)\n",
        "    metrics.update(combined_wam)\n",
        "  \n",
        "  return metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyY54tDO2XHD"
      },
      "source": [
        "# Experiment main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QEqSOh15qeD"
      },
      "source": [
        "### Development loop\n",
        "useful for toggling settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eoKg_0K2cr6"
      },
      "source": [
        "# steps = [\"max_length\", \"target_size\", \"ws_mean\", \"ws_var\", \"shuffle_labels\",\"mask_prob\", \"spex_mode\"]\n",
        "# tags = [f\"{step}: {config[step]}\" for step in steps]\n",
        "# group = \" - \".join(tags)\n",
        "\n",
        "# wandb.init(project=\"thesis-\"+config[\"dataset\"],\n",
        "#            reinit=True,\n",
        "#            id=config[\"id\"],\n",
        "#            name=f'{config[\"name\"]} ({config[\"id\"]})',\n",
        "#            notes=config[\"remark\"],\n",
        "#            save_code=True,\n",
        "#            tags=tags,\n",
        "#            group=group,\n",
        "#            config=config)\n",
        "\n",
        "# import numpy as np\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from transformers import TFBertModel\n",
        "\n",
        "# train_data, class_names = load_dataset(config[\"dataset\"], split=\"train\", return_class_names=True)\n",
        "# test_data = load_dataset(config[\"dataset\"], split=\"dev\", head=False)\n",
        "\n",
        "# if not label_names:\n",
        "#   label_names = class_names\n",
        "\n",
        "# np.random.seed(config[\"seed\"])\n",
        "# target_data_seeds = np.random.randint(low=1, high=10000, size=config[\"n_experiments\"], )\n",
        "\n",
        "# results = []\n",
        "# for run, seed in enumerate(target_data_seeds):\n",
        "#   print(f\"\\nExecuting run {run+1}/{config['n_experiments']}\\n\")\n",
        "  \n",
        "#   metrics = {}\n",
        "\n",
        "#   model = TFBertModel.from_pretrained(PRETRAINED_MODEL)\n",
        "#   weak_df, target_df = train_test_split(train_data, test_size=config[\"target_size\"], random_state=seed, stratify=train_data.label)\n",
        "  \n",
        "#   if config[\"finetune_am\"]:\n",
        "#     print(\"Initial Evaluation\")\n",
        "#     extrinsic_metrics = extrinsic_evaluation(target_df, test_data, finetune=False, prefix=\"Initial\")\n",
        "#     metrics.update(extrinsic_metrics)\n",
        "\n",
        "#   if config[\"spanbert\"] is not False: \n",
        "#     print(\"SpanBERT training\")\n",
        "#     model = spanbert_training(weak_df, target_df, model)\n",
        "\n",
        "#     if config[\"finetune_am\"]:\n",
        "#       print(\"After SpanBERT Evaluation\")\n",
        "#       extrinsic_metrics = extrinsic_evaluation(target_df, test_data, finetune=True, model=model, prefix=\"After SpanBERT\")\n",
        "#       metrics.update(extrinsic_metrics)\n",
        "\n",
        "  \n",
        "#   if config[\"spex\"] is not False:\n",
        "\n",
        "#     if config[\"spex\"] in [\"pretrain\",\"both\"]:\n",
        "#       print(\"Simulating Weak Supervision\")\n",
        "#       weak_df, ws_metrics = simulate_ws(weak_df)\n",
        "#       metrics.update(ws_metrics)\n",
        "\n",
        "#       print(\"Span Extractive pre-training\")\n",
        "#       model = spex_training(weak_df, model, log_name=\"pretrain\", epochs=config[\"spex_pt_epochs\"])\n",
        "\n",
        "#       if config[\"augmentation\"] == \"hetero\":\n",
        "#         print(\"Target Analysis\")\n",
        "#         analysis = target_analysis(target_df, model)\n",
        "#         target_complexity = {\"target_complexity\": analysis[0].mean()}\n",
        "#         wandb.log(target_complexity)\n",
        "#         metrics.update(target_complexity)\n",
        "\n",
        "#       else:\n",
        "#         analysis = None\n",
        "\n",
        "#     if config[\"spex\"] in [\"finetune\",\"both\"]:\n",
        "#       print(\"Span Extractive finetuning\")\n",
        "#       model = spex_training(target_df, model, log_name=\"finetune\", epochs=config[\"spex_ft_epochs\"])\n",
        "\n",
        "#     if config[\"finetune_am\"]:\n",
        "#       print(\"After SpanEx Evaluation\")\n",
        "#       extrinsic_metrics = extrinsic_evaluation(target_df, test_data, finetune=True, model=model, prefix=\"After SPEX\")\n",
        "#       metrics.update(extrinsic_metrics)\n",
        "\n",
        "#   if config[\"augmentation\"] is not False:\n",
        "#     print(\"Augmentation model training\")\n",
        "#     model = augmentation_training(target_df, model)\n",
        "    \n",
        "#     print(\"Target Augmentation\")\n",
        "#     augmented_df, type_token_ratio = target_augmentation(target_df, model, analysis, head=10)\n",
        "#     metrics.update(type_token_ratio)\n",
        "\n",
        "#     combined_df = pd.concat([target_df, augmented_df], ignore_index=True)\n",
        "\n",
        "#     # print(\"Semantic Evaluation\")\n",
        "#     # semantic cross entropy = intrinsic_evaluaton(augmented_df)\n",
        "\n",
        "#   else:\n",
        "#     combined_df = target_df\n",
        "\n",
        "#   print(\"Extrinsic Evaluation\")\n",
        "\n",
        "#   print(\"only augmented data\")\n",
        "#   extrinsic_metrics = extrinsic_evaluation(augmented_df, test_data, finetune=False, prefix=\"Only AUG\")\n",
        "#   metrics.update(extrinsic_metrics)\n",
        "\n",
        "#   print(\"only target but equal amount of data\")\n",
        "#   extrinsic_metrics = extrinsic_evaluation(target_df, test_data, finetune=False, prefix=\"Only target equal epochs\", epochs=config[\"extrinsic_epochs\"] * (config[\"n_target_aug\"] + 1))\n",
        "#   metrics.update(extrinsic_metrics)\n",
        "  \n",
        "#   print(\"Combined dataset\")\n",
        "#   extrinsic_metrics = extrinsic_evaluation(combined_df, test_data, finetune=False, prefix=\"Combined\")\n",
        "#   metrics.update(extrinsic_metrics)\n",
        "\n",
        "#   if config[\"finetune_am\"]: \n",
        "#     print(\"Combined dataset with finetuned model\")\n",
        "#     extrinsic_metrics = extrinsic_evaluation(combined_df, test_data, finetune=True, model=model, prefix=\"Combined wAM\")\n",
        "#     metrics.update(extrinsic_metrics)\n",
        "\n",
        "#   print(\"\\nRun Metrics\\n\")\n",
        "#   display(metrics)\n",
        "#   results.append(metrics)\n",
        "\n",
        "#   #aggegate metrics\n",
        "#   overall_metrics = aggregate_metrics(results)\n",
        "#   wandb.log(overall_metrics)\n",
        "#   wandb.run.summary.update(overall_metrics)\n",
        "\n",
        "# print(\"\\nOverall Metrics\\n\")\n",
        "# display(overall_metrics)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uR1oTSx6BxB"
      },
      "source": [
        "### Test loop\n",
        "useful for paper results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVpZkvwppQMQ"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import TFBertModel\n",
        "\n",
        "main_data, class_names = load_dataset(config[\"dataset\"], split=\"train\", return_class_names=True)\n",
        "dev_df = load_dataset(config[\"dataset\"], split=\"dev\", head=False)\n",
        "\n",
        "if not label_names:\n",
        "  label_names = class_names\n",
        "\n",
        "np.random.seed(config[\"seed\"])\n",
        "target_data_seeds = np.random.randint(low=1, high=10000, size=config[\"n_experiments\"], )\n",
        "aug_preview = 5\n",
        "\n",
        "#W&B group name\n",
        "steps = [\"max_length\", \"target_size\", \"spex_pt_epochs\", \"spex_ft_epochs\", \"aug_epochs\",\"mask_prob\", \"spex_mode\"]\n",
        "tags = [f\"{step}_{config[step]}\" for step in steps]\n",
        "group = \" - \".join(tags)\n",
        "\n",
        "for run, seed in enumerate(target_data_seeds):\n",
        "  print(f\"\\nExecuting run {run+1}/{config['n_experiments']}\\n\")\n",
        "\n",
        "  #skip runs if continuing from new point\n",
        "  if run < SKIP_RUNS:\n",
        "    print(f\"Skipping run {run+1}\")\n",
        "    continue\n",
        "  \n",
        "  config[\"id\"] = str(secrets.token_hex(4))\n",
        "\n",
        "  wandb.init(project=\"thesis-\"+config[\"dataset\"],\n",
        "            reinit=True,\n",
        "            id=config[\"id\"],\n",
        "            name=f'{config[\"name\"]} - {run+1} ({config[\"id\"]})',\n",
        "            notes=config[\"remark\"],\n",
        "            save_code=True,\n",
        "            tags=tags,\n",
        "            group=group,\n",
        "            config=config)\n",
        "  \n",
        "  #already train spanbert before hand just in case\n",
        "  # from_spanbert(main_data, dev_df)\n",
        "\n",
        "  # prep dataset\n",
        "  # sample a test and target df, both same percentage on total data\n",
        "  train_df, test_df = train_test_split(main_data, test_size=config[\"target_size\"], random_state=seed, stratify=main_data.label)\n",
        "  weak_df, target_df = train_test_split(train_df, test_size=config[\"target_size\"] / (1-config[\"target_size\"]), random_state=seed, stratify=train_df.label)\n",
        "\n",
        "  # train model for semantic evaluation and reference performance\n",
        "  eval_model, top_metrics = train_eval_model(weak_df, dev_df, test_df)\n",
        "\n",
        "  # generate weak supervision\n",
        "  weak_df, ws_metrics = simulate_ws(weak_df)\n",
        "\n",
        "  # initial evaluation\n",
        "  print(\"Initial Evaluation\")\n",
        "  initial_metrics = extrinsic_evaluation(target_df, test_df, dev_df, finetune=False, prefix=\"Baseline\")\n",
        "\n",
        "  #vanilla augmentation train + eval\n",
        "  prefix = \"Benchmark\"\n",
        "  print(f\"\\n{prefix} Evaluation\\n\")\n",
        "  model = TFBertModel.from_pretrained(PRETRAINED_MODEL)\n",
        "  model = augmentation_training(target_df, dev_df, model, logname=prefix)\n",
        "  augmented_df, type_token_ratio = target_augmentation(target_df, \n",
        "                                                       model, \n",
        "                                                       analysis=None,\n",
        "                                                       mask_strategy=\"base\",\n",
        "                                                       prob_labels=False,\n",
        "                                                       prefix=prefix,\n",
        "                                                       head=aug_preview)\n",
        "\n",
        "  semantic_quality =  semantic_eval(eval_model, augmented_df, prefix=prefix)\n",
        "\n",
        "  eval_metrics = augmentation_eval(target_df, augmented_df, test_df, dev_df, model, prefix=prefix)\n",
        "\n",
        "  # spex ft\n",
        "  # vanilla augmentation train + eval\n",
        "  prefix = \"spex-ft\"\n",
        "  print(f\"\\n{prefix} Evaluation\\n\")\n",
        "  model = TFBertModel.from_pretrained(PRETRAINED_MODEL)\n",
        "  model = spex_training(target_df, dev_df, model, log_name=prefix+\" finetune\", epochs=config[\"spex_ft_epochs\"])\n",
        "  model = augmentation_training(target_df, dev_df, model, logname=prefix)\n",
        "  augmented_df, type_token_ratio = target_augmentation(target_df, \n",
        "                                                       model, \n",
        "                                                       analysis=None,\n",
        "                                                       mask_strategy=\"base\",\n",
        "                                                       prob_labels=False,\n",
        "                                                       prefix=prefix,\n",
        "                                                       head=aug_preview)\n",
        "\n",
        "  semantic_quality =  semantic_eval(eval_model, augmented_df, prefix=prefix)\n",
        "\n",
        "  eval_metrics = augmentation_eval(target_df, augmented_df, test_df, dev_df, model, prefix=prefix)\n",
        "\n",
        "  ##if we have ws\n",
        "  # spex pt\n",
        "  # spex ft\n",
        "  # vanilla augmentation train + eval\n",
        "  prefix = \"spex-full\"\n",
        "  print(f\"\\n{prefix} Evaluation\\n\")\n",
        "  model = TFBertModel.from_pretrained(PRETRAINED_MODEL)\n",
        "  model = spex_training(weak_df, dev_df, model, log_name=prefix+\" pretrain\", epochs=config[\"spex_pt_epochs\"])\n",
        "  model = spex_training(target_df, dev_df, model, log_name=prefix+\" finetune\", epochs=config[\"spex_ft_epochs\"])\n",
        "\n",
        "  model = augmentation_training(target_df, dev_df, model, logname=prefix)\n",
        "  augmented_df, type_token_ratio = target_augmentation(target_df, \n",
        "                                                       model, \n",
        "                                                       analysis=None,\n",
        "                                                       mask_strategy=\"base\",\n",
        "                                                       prob_labels=False,\n",
        "                                                       prefix=prefix,\n",
        "                                                       head=aug_preview)\n",
        "\n",
        "  semantic_quality =  semantic_eval(eval_model, augmented_df, prefix=prefix)\n",
        "\n",
        "  eval_metrics = augmentation_eval(target_df, augmented_df, test_df, dev_df, model, prefix=prefix)\n",
        "\n",
        "  ##if we have spanbert\n",
        "  # load spanbert\n",
        "  # spex pt\n",
        "  # target analsyis\n",
        "  # spex ft\n",
        "  # vanilla augmentation train\n",
        "  # vanilla augmentation eval\n",
        "  # heterogenous augmentation eval\n",
        "  # hetero + prob_label augmentation eval\n",
        "  prefix = \"wSB\"\n",
        "  print(f\"\\n{prefix} Evaluation\\n\")\n",
        "\n",
        "  model = from_spanbert(main_data, dev_df)\n",
        "  model = spex_training(weak_df, dev_df, model, log_name=prefix+\" pretrain\", epochs=config[\"spex_pt_epochs\"])\n",
        "\n",
        "  analysis = target_analysis(target_df, model)\n",
        "  target_complexity = {\"target_complexity\": analysis[0].mean()}\n",
        "  wandb.log(target_complexity)\n",
        "\n",
        "  model = spex_training(target_df, dev_df, model, log_name=prefix+\" finetune\", epochs=config[\"spex_ft_epochs\"])\n",
        "  model = augmentation_training(target_df, dev_df, model, logname=prefix)\n",
        "  \n",
        "  eval_configs = [\"sb+spex\", \"sb+spex+hetero\", \"sb+spex+hetero+probs\"]\n",
        "  for i, name in enumerate(eval_configs):\n",
        "    mask_strategy = \"base\" if i == 0 else \"hetero\"\n",
        "    prob_labels = False if i <= 1 else True\n",
        "\n",
        "    augmented_df, type_token_ratio = target_augmentation(target_df, \n",
        "                                                        model, \n",
        "                                                        analysis=analysis,\n",
        "                                                        mask_strategy=mask_strategy,\n",
        "                                                        prob_labels=prob_labels,\n",
        "                                                        prefix=name,\n",
        "                                                        head=aug_preview)\n",
        "\n",
        "    semantic_quality =  semantic_eval(eval_model, augmented_df, prefix=name)\n",
        "\n",
        "    eval_metrics = augmentation_eval(target_df, augmented_df, test_df, dev_df, model, prefix=name)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
